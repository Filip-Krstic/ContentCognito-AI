# ContentCognito-AI: Instagram Reels Content & Personality Profiling

**ContentCognito-AI** is a cutting-edge Python suite meticulously designed for in-depth analysis of Instagram Reels content. By leveraging direct interaction with a physically connected Android device, it ethically extracts rich visual and textual data. The project employs advanced AI techniques, including sophisticated image captioning, Optical Character Recognition (OCR), and sentiment analysis, culminating in a comprehensive behavioral profile generated by a **custom-trained MBTI personality classification model**.

**This project is developed strictly for academic research and educational purposes. A research paper detailing its methodology and findings is currently in preparation.**

## Key Features

* **Ethical Data Acquisition**:
    * **Requires a physical Android device connected via USB Debugging (ADB)**. This design choice is fundamental to the project's ethical framework, intentionally creating a physical barrier to prevent unauthorized remote execution. It ensures data collection is transparent, localized, and under explicit user control, fostering responsible research practices.
* **Real-time Mobile Interaction**:
    * Utilizes `ADB (Android Debug Bridge)` commands for device control and screenshot capture.
    * Integrates `scrcpy` for real-time screen mirroring and automated UI interaction (e.g., navigating Reels), facilitating precise data extraction from dynamic content.
* **Advanced Computer Vision**:
    * **AI-Powered Image Captioning (BLIP)**: Employs state-of-the-art BLIP models to generate descriptive textual captions for visual elements within Reels, providing deep contextual understanding of the content.
    * **Optical Character Recognition (OCR)**: Leverages `EasyOCR` to accurately extract text directly from images and videos (e.g., overlaid text, subtitles), enriching the textual dataset.
    * **Profile Matching**: Compares dynamic screenshots against a user-defined profile image to identify and focus data collection on specific feeds or target profiles.
* **Natural Language Processing (NLP)**:
    * **Sentiment Analysis**: Integrates `VADER Sentiment` and `TextBlob` to perform fine-grained analysis of the emotional tone of all extracted textual data, quantifying content positivity, negativity, and neutrality.
* **Custom Behavioral Profiling (MBTI)**:
    * Features a **unique, custom-trained MBTI classification model**, developed entirely for this project on a specialized dataset. This model analyzes both the extracted text from Reels (descriptions, comments, captions) and the AI-generated visual captions to infer personality types likely associated with the content consumed, providing novel insights into user engagement.
* **Comprehensive Data Management**:
    * All raw extracted data and processed analytical results (text, captions, sentiments, hashtags, MBTI predictions) are robustly stored in a local `SQLite` database (`p-info.db`) for structured access, querying, and further scientific analysis.
* **Intuitive Graphical User Interface (GUI)**: Built with `Tkinter`, the application provides a seamless user experience:
    * A central `MAIN` control panel for orchestrating the data acquisition and analysis workflow.
    * A `Config Editor` for precise setup of screen dimensions, definition of data extraction regions, and management of the target profile image.
    * A `Factsheet Viewer` for dynamic visualization of the comprehensive analysis, including MBTI breakdowns, top hashtags, detailed sentiment distributions (pie charts), and an interactive gallery of analyzed images/videos with their generated BLIP captions.
* **Automation & Concurrency**:
    * Utilizes `pyautogui` for precise programmatic UI interaction (mouse control, keyboard inputs).
    * Employs `threading` to enable concurrent execution of computationally intensive tasks (e.g., ADB commands, AI model inference) alongside GUI operations, ensuring a responsive and efficient research tool.
* **Video Content Processing**: Includes capabilities for processing and cropping extracted video files (`ffmpeg-python`), ensuring that only relevant content areas are analyzed.

## Purpose & Ethical Statement

This project is conceived as a powerful **research and educational tool**. Its primary goal is to explore the correlations between social media content consumption patterns (specifically Instagram Reels) and potential behavioral insights, such as personality types. The intentional requirement of a physically connected device underscores our commitment to ethical data handling in research, ensuring transparency and preventing unintended remote surveillance. The methodology and findings of this project will form the basis of an upcoming **research paper**, which will be made publicly available.

## Technologies Used

* **Python**: Core programming language.
* **`tkinter`**: For building the graphical user interface.
* **`subprocess` & `os`**: For executing system commands (e.g., ADB, scrcpy).
* **`pyautogui` & `keyboard`**: For automating UI interactions (mouse clicks, key presses).
* **`pygetwindow`**: For window management (e.g., bringing scrcpy window to front).
* **`easyocr`**: For Optical Character Recognition.
* **`sqlite3`**: For local database management.
* **`cv2` (OpenCV)**: For image processing and comparison.
* **`numpy`**: For numerical operations.
* **`textblob` & `vaderSentiment`**: For sentiment analysis.
* **`torch` & `transformers` (Hugging Face)**: For advanced AI models like BLIP (image captioning).
* **`PIL` (Pillow) & `ImageTk`**: For image manipulation and display in Tkinter.
* **`json`**: For handling JSON data.
* **`ffmpeg-python`**: For video processing (e.g., cropping).
* **`base64`**: For encoding/decoding image data.
* **`re`**: For regular expressions.
* **`difflib`**: For string comparison.
* **`threading`**: For concurrent execution.
* **`pandas`**: For data manipulation in `factsheet_logic`.
* **`scikit-learn` (`sklearn`)**: For `TfidfVectorizer` and the **custom MBTI model**.
* **`scipy.sparse`**: For handling sparse matrices (`hstack`).
* **`joblib`**: For saving/loading trained machine learning models.
* **`matplotlib.pyplot`**: For data visualization (charts, plots).

## Installation

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/ReelInsight-AI.git](https://github.com/your-username/ReelInsight-AI.git)
    cd ReelInsight-AI
    ```

2.  **Create a virtual environment (highly recommended):**
    ```bash
    python -m venv venv
    # On Windows
    venv\Scripts\activate
    # On macOS/Linux
    source venv/bin/activate
    ```

3.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Install ADB (Android Debug Bridge) & scrcpy:**
    * **ADB**: Download and set up ADB from the [Android Developers website](https://developer.android.com/tools/releases/platform-tools). Ensure `adb` is in your system's PATH.
    * **scrcpy**: Download the latest release of `scrcpy` from its [GitHub repository](https://github.com/Genymobile/scrcpy/releases). Place the `scrcpy` executable in a location accessible by your system's PATH, or directly in your project folder.

5.  **Prepare your Android Device for Debugging:**
    * Enable **Developer Options** on your Android phone (typically by tapping "Build number" seven times in "Settings > About phone").
    * Within Developer Options, enable **USB Debugging**.
    * Connect your phone to your PC via USB. When prompted on your phone, **authorize USB Debugging** for your computer.

## Usage Workflow

The project operates through a meticulously designed sequence of steps, managed via the `MAIN.py` GUI:

1.  **Launch the Main Application:**
    ```bash
    python MAIN.py
    ```
    This will open the main control panel.

2.  **Configure Settings (Config Editor):**
    * Click the "Run Config Editor" button.
    * In the Config Editor, set your pixel dimensions (X:Y) based on your mobile device's screen resolution or the specific area of interest for monitoring.
    * **Upload your target profile picture (`prof.png`)**: This image is crucial for the `data_researcher` to identify specific content feeds on Instagram. Ensure `prof.png` is placed in the `temp_out/` directory.
    * Save your configurations.

3.  **Collect Data (Data Researcher):**
    * **Crucially, ensure your mobile phone is connected with USB Debugging enabled and authorized.**
    * From the `MAIN.py` panel, click "Run Data Researcher".
    * This script will automate interaction with your phone (e.g., launching Instagram, navigating Reels), capture screenshots, extract text/images using OCR and BLIP, and store raw data into `temp_out/p-info.db` and other temporary files.
    * Monitor the `MAIN.py` GUI, which will indicate the current database row count, signaling data collection progress.

4.  **Process Data (Factsheet Logic):**
    * Once sufficient data is collected (the "Data Researcher" button in `MAIN.py` will turn green, indicating enough rows), click "Run Factsheet Logic".
    * This script will process the raw data from `p-info.db`, perform in-depth sentiment analysis, identify prevalent hashtags, and execute the **custom MBTI prediction model**.
    * The analytical results will be consolidated and saved to `temp_out/temp_out_x1.txt`.

5.  **View Results (View Factsheet):**
    * After `Factsheet Logic` completes its processing, click "View Factsheet" from the `MAIN.py` panel.
    * This will open a new GUI window, providing a comprehensive visual report: detailed MBTI personality percentages, a list of top trending hashtags, clear pie charts illustrating sentiment distributions (optimist vs. pessimist), and an interactive gallery of analyzed images/videos with their corresponding AI-generated BLIP captions.

## Project Structure

├── MAIN.py                     # Central GUI to control the entire workflow
├── config_editor.py            # GUI for setting up screen coordinates, profile picture, etc.
├── data_researcher.py          # Core script for mobile interaction, data extraction (screenshots, OCR, BLIP)
├── factsheet_logic.py          # Script for data processing, sentiment analysis, custom MBTI prediction
├── view_factsheet.py           # GUI for visualizing the comprehensive analytical factsheet
├── README.md                   # This documentation file
├── requirements.txt            # Python package dependencies
├── .gitignore                  # Files/folders to be ignored by Git
├── LICENSE                     # Project's open-source license (MIT)
├── configurables/              # Directory for project configuration data
│   ├── hashtag.txt             # Example: List of hashtags to monitor
│   └── getout.txt              # Example: Coordinates for "get out" button or similar
├── data/                       # Directory for machine learning models and related data
│   ├── tfidf_vectorizer.joblib # Pre-trained TF-IDF vectorizer for text feature extraction
│   └── mbti_model.joblib       # Your custom-trained MBTI classification model
└── temp_out/                   # Temporary output directory (Ignored by Git)
├── p-info.db               # SQLite database storing all extracted raw and processed data
├── prof.png                # User-defined profile image for content matching
├── temp_screenshot.png     # Temporary file for raw screenshots from device
├── temp_out_x1.txt         # Consolidated analytical factsheet data for view_factsheet.py
└── c*.png / c*.mp4         # Cropped image/video outputs for analysis


## Contribution & Further Research

We welcome contributions to enhance **ReelInsight AI**. Feel free to fork the repository, propose improvements, or report issues. As this project is primarily for research, we encourage collaboration on expanding its capabilities or leveraging it for new academic inquiries.

## License

This project is licensed under the MIT License - see the `LICENSE` file for details.
